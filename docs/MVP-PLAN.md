# üöÄ MVP - Validaci√≥n de Scraping hide.mn

## üéØ Objetivo del MVP

Crear una prueba de concepto m√≠nima para validar que es posible extraer proxies de https://hide.mn/es/proxy-list/?type=s#list antes de desarrollar la aplicaci√≥n completa.

---

## üìã Alcance del MVP

### ‚úÖ **Lo que S√ç incluye:**

- Script b√°sico de scraping sin UI
- Detecci√≥n de estructura DOM de la p√°gina
- Extracci√≥n de proxies de una p√°gina
- Validaci√≥n b√°sica de formato de datos
- Test de conectividad simple (sin Playwright)

### ‚ùå **Lo que NO incluye:**

- Interfaz React completa
- Paginaci√≥n autom√°tica
- Validaci√≥n con Playwright
- Estado global con Context
- UI responsive

---

## üõ†Ô∏è Stack del MVP

```bash
# Dependencias m√≠nimas
bun add cheerio
bun add -D @types/cheerio tsx
```

**Herramientas:**

- **HTTP Client**: fetch nativo para requests
- **HTML Parser**: cheerio para parsing
- **Runtime**: tsx para ejecutar TypeScript directamente

---

## üìÅ Estructura del MVP

```
mvp/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scraper-test.ts      # Script principal de prueba
‚îÇ   ‚îú‚îÄ‚îÄ types.ts             # Tipos b√°sicos
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts             # Utilidades de validaci√≥n
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ scraped-data.json    # Datos extra√≠dos (gitignored)
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README-MVP.md
```

---

## üîß Implementaci√≥n del MVP

### **Archivo 1: `mvp/src/types.ts`**

```typescript
export interface ProxyData {
  ip: string;
  port: number;
  protocol: "http" | "https";
  country?: string;
  anonymity?: string;
  uptime?: string;
}

export interface ScrapingResult {
  success: boolean;
  proxiesFound: number;
  data: ProxyData[];
  errors: string[];
  pageStructure: {
    hasTable: boolean;
    tableRows: number;
    paginationFound: boolean;
    totalPages?: number;
  };
}
```

### **Archivo 2: `mvp/src/utils.ts`**

```typescript
export const isValidIP = (ip: string): boolean => {
  const ipRegex =
    /^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$/;
  return ipRegex.test(ip);
};

export const isValidPort = (port: string | number): boolean => {
  const portNum = typeof port === "string" ? parseInt(port) : port;
  return !isNaN(portNum) && portNum > 0 && portNum <= 65535;
};

export const detectProtocol = (text: string): "http" | "https" => {
  return text.toLowerCase().includes("https") ? "https" : "http";
};

export const cleanText = (text: string): string => {
  return text.trim().replace(/\s+/g, " ");
};
```

### **Archivo 3: `mvp/src/scraper-test.ts`**

```typescript
import * as cheerio from "cheerio";
import { writeFileSync } from "fs";
import { ProxyData, ScrapingResult } from "./types";
import { isValidIP, isValidPort, detectProtocol, cleanText } from "./utils";

class HideMnScraper {
  private readonly baseUrl = "https://hide.mn/es/proxy-list/?type=s";
  private readonly userAgent =
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36";

  async testScraping(): Promise<ScrapingResult> {
    const result: ScrapingResult = {
      success: false,
      proxiesFound: 0,
      data: [],
      errors: [],
      pageStructure: {
        hasTable: false,
        tableRows: 0,
        paginationFound: false,
      },
    };

    try {
      console.log("üîç Iniciando test de scraping...");

      // 1. Fetch de la p√°gina principal
      const html = await this.fetchPage(this.baseUrl);
      console.log("‚úÖ P√°gina obtenida exitosamente");

      // 2. Analizar estructura de la p√°gina
      const $ = cheerio.load(html);
      this.analyzePageStructure($, result);

      // 3. Intentar extraer proxies
      const proxies = this.extractProxies($);
      result.data = proxies;
      result.proxiesFound = proxies.length;

      // 4. Validar datos extra√≠dos
      const validProxies = proxies.filter(
        (p) => isValidIP(p.ip) && isValidPort(p.port)
      );
      console.log(`üìä Proxies encontrados: ${proxies.length}`);
      console.log(`‚úÖ Proxies v√°lidos: ${validProxies.length}`);

      result.success = validProxies.length > 0;

      // 5. Guardar resultados
      this.saveResults(result);

      return result;
    } catch (error) {
      console.error("‚ùå Error durante scraping:", error);
      result.errors.push(
        error instanceof Error ? error.message : String(error)
      );
      return result;
    }
  }
  private async fetchPage(url: string): Promise<string> {
    const response = await fetch(url, {
      headers: {
        "User-Agent": this.userAgent,
        Accept:
          "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Accept-Encoding": "gzip, deflate",
        Connection: "keep-alive",
      },
      signal: AbortSignal.timeout(10000),
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    return await response.text();
  }

  private analyzePageStructure(
    $: cheerio.CheerioAPI,
    result: ScrapingResult
  ): void {
    console.log("üîç Analizando estructura de la p√°gina...");

    // Buscar tablas posibles
    const tables = $("table");
    console.log(`üìã Tablas encontradas: ${tables.length}`);

    if (tables.length > 0) {
      result.pageStructure.hasTable = true;

      // Analizar la tabla m√°s probable
      tables.each((i, table) => {
        const $table = $(table);
        const rows = $table.find("tr");
        console.log(`üìã Tabla ${i + 1}: ${rows.length} filas`);

        if (rows.length > result.pageStructure.tableRows) {
          result.pageStructure.tableRows = rows.length;
        }
      });
    }

    // Buscar paginaci√≥n
    const paginationSelectors = [
      ".pagination",
      ".pager",
      ".page-numbers",
      '[class*="page"]',
      '[class*="pagination"]',
    ];

    for (const selector of paginationSelectors) {
      const paginationEl = $(selector);
      if (paginationEl.length > 0) {
        result.pageStructure.paginationFound = true;
        console.log(`üìÑ Paginaci√≥n encontrada: ${selector}`);

        // Intentar extraer n√∫mero total de p√°ginas
        const pageNumbers = paginationEl
          .find("a, span")
          .map((_, el) => {
            const text = $(el).text().trim();
            return parseInt(text);
          })
          .get()
          .filter((num) => !isNaN(num));

        if (pageNumbers.length > 0) {
          result.pageStructure.totalPages = Math.max(...pageNumbers);
        }
        break;
      }
    }
  }

  private extractProxies($: cheerio.CheerioAPI): ProxyData[] {
    console.log("üï∑Ô∏è Extrayendo proxies...");
    const proxies: ProxyData[] = [];

    // M√∫ltiples estrategias de extracci√≥n
    const tableSelectors = [
      "table tr",
      ".proxy-list tr",
      '[class*="proxy"] tr',
      "tbody tr",
    ];

    for (const selector of tableSelectors) {
      const rows = $(selector);
      console.log(`üîç Probando selector: ${selector} (${rows.length} filas)`);

      if (rows.length > 1) {
        // M√°s de 1 fila (excluyendo header)
        rows.each((index, row) => {
          if (index === 0) return; // Skip header row

          const $row = $(row);
          const cells = $row.find("td");

          if (cells.length >= 2) {
            const proxy = this.extractProxyFromRow($, $row, cells);
            if (proxy) {
              proxies.push(proxy);
            }
          }
        });

        if (proxies.length > 0) {
          console.log(`‚úÖ Extracci√≥n exitosa con selector: ${selector}`);
          break; // Si encontramos proxies, no necesitamos probar otros selectores
        }
      }
    }

    return proxies;
  }

  private extractProxyFromRow(
    $: cheerio.CheerioAPI,
    $row: cheerio.Cheerio<cheerio.Element>,
    cells: cheerio.Cheerio<cheerio.Element>
  ): ProxyData | null {
    try {
      // Estrategias m√∫ltiples para extraer IP y puerto
      const firstCell = cleanText($(cells[0]).text());
      const secondCell = cleanText($(cells[1]).text());

      let ip = "";
      let port = 0;

      // Estrategia 1: IP en primera celda, puerto en segunda
      if (isValidIP(firstCell) && isValidPort(secondCell)) {
        ip = firstCell;
        port = parseInt(secondCell);
      }
      // Estrategia 2: IP:Puerto en primera celda
      else if (firstCell.includes(":")) {
        const [ipPart, portPart] = firstCell.split(":");
        if (isValidIP(ipPart.trim()) && isValidPort(portPart.trim())) {
          ip = ipPart.trim();
          port = parseInt(portPart.trim());
        }
      }

      if (!ip || !port) {
        return null;
      }

      // Extraer informaci√≥n adicional
      const protocol = detectProtocol($row.text());
      const country = this.extractCountry($, $row, cells);
      const anonymity = this.extractAnonymity($, $row, cells);

      return {
        ip,
        port,
        protocol,
        country,
        anonymity,
      };
    } catch (error) {
      console.warn("‚ö†Ô∏è Error extrayendo proxy de fila:", error);
      return null;
    }
  }

  private extractCountry(
    $: cheerio.CheerioAPI,
    $row: cheerio.Cheerio<cheerio.Element>,
    cells: cheerio.Cheerio<cheerio.Element>
  ): string | undefined {
    // Buscar pa√≠s en diferentes posiciones
    for (let i = 2; i < Math.min(cells.length, 6); i++) {
      const cellText = cleanText($(cells[i]).text());

      // Si parece un pa√≠s (2-3 letras o nombre com√∫n)
      if (
        cellText.length === 2 ||
        cellText.length === 3 ||
        ["United States", "Germany", "France", "China"].some((country) =>
          cellText.toLowerCase().includes(country.toLowerCase())
        )
      ) {
        return cellText;
      }
    }

    return undefined;
  }

  private extractAnonymity(
    $: cheerio.CheerioAPI,
    $row: cheerio.Cheerio<cheerio.Element>,
    cells: cheerio.Cheerio<cheerio.Element>
  ): string | undefined {
    const text = $row.text().toLowerCase();

    if (text.includes("elite") || text.includes("high")) return "Elite";
    if (text.includes("anonymous")) return "Anonymous";
    if (text.includes("transparent")) return "Transparent";

    return undefined;
  }

  private saveResults(result: ScrapingResult): void {
    try {
      const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
      const filename = `results/scraping-test-${timestamp}.json`;

      writeFileSync(filename, JSON.stringify(result, null, 2));
      console.log(`üíæ Resultados guardados en: ${filename}`);
    } catch (error) {
      console.warn("‚ö†Ô∏è No se pudieron guardar los resultados:", error);
    }
  }
}

// Ejecutar test
async function runMVP() {
  console.log("üöÄ Iniciando MVP de Scraping hide.mn\n");

  const scraper = new HideMnScraper();
  const result = await scraper.testScraping();

  console.log("\nüìä RESULTADOS DEL MVP:");
  console.log("=====================================");
  console.log(`‚úÖ √âxito: ${result.success ? "S√ç" : "NO"}`);
  console.log(`üìã Proxies encontrados: ${result.proxiesFound}`);
  console.log(`üèóÔ∏è Estructura encontrada:`);
  console.log(`   - Tabla: ${result.pageStructure.hasTable ? "S√ç" : "NO"}`);
  console.log(`   - Filas: ${result.pageStructure.tableRows}`);
  console.log(
    `   - Paginaci√≥n: ${result.pageStructure.paginationFound ? "S√ç" : "NO"}`
  );
  if (result.pageStructure.totalPages) {
    console.log(`   - P√°ginas totales: ${result.pageStructure.totalPages}`);
  }

  if (result.errors.length > 0) {
    console.log(`‚ùå Errores: ${result.errors.length}`);
    result.errors.forEach((error) => console.log(`   - ${error}`));
  }

  if (result.data.length > 0) {
    console.log("\nüîç MUESTRA DE DATOS:");
    console.log("=====================================");
    result.data.slice(0, 3).forEach((proxy, i) => {
      console.log(`${i + 1}. ${proxy.ip}:${proxy.port} (${proxy.protocol})`);
      if (proxy.country) console.log(`   Pa√≠s: ${proxy.country}`);
      if (proxy.anonymity) console.log(`   Anonimato: ${proxy.anonymity}`);
    });
  }

  console.log("\nüéØ CONCLUSI√ìN:");
  console.log("=====================================");
  if (result.success) {
    console.log("‚úÖ El scraping es FACTIBLE");
    console.log("‚úÖ Se puede proceder con el desarrollo completo");
  } else {
    console.log("‚ùå El scraping presenta PROBLEMAS");
    console.log("‚ùå Se necesita revisar la estructura de la p√°gina");
  }
}

// Ejecutar si es el archivo principal
if (require.main === module) {
  runMVP().catch(console.error);
}

export { HideMnScraper };
```

---

## üöÄ Comandos para Ejecutar el MVP

### **Setup:**

```bash
# Crear directorio MVP
mkdir mvp && cd mvp

# Inicializar proyecto
bun init -y

# Instalar dependencias
bun add cheerio
bun add -D @types/cheerio tsx typescript @types/node

# Crear estructura
mkdir -p src results
```

### **Ejecuci√≥n:**

```bash
# Ejecutar test de scraping
bunx tsx src/scraper-test.ts

# O a√±adir al package.json:
bun run mvp
```

---

## üìã Checklist del MVP

### **Preparaci√≥n:**

- [ ] Crear directorio `mvp/`
- [ ] Instalar dependencias m√≠nimas
- [ ] Configurar TypeScript b√°sico
- [ ] Crear estructura de archivos

### **Implementaci√≥n:**

- [ ] Implementar tipos b√°sicos
- [ ] Crear utilidades de validaci√≥n
- [ ] Desarrollar scraper principal
- [ ] A√±adir an√°lisis de estructura DOM
- [ ] Implementar m√∫ltiples estrategias de extracci√≥n

### **Testing:**

- [ ] Ejecutar test contra hide.mn
- [ ] Verificar extracci√≥n de datos
- [ ] Analizar estructura de paginaci√≥n
- [ ] Validar formato de proxies
- [ ] Documentar hallazgos

### **Validaci√≥n:**

- [ ] ‚úÖ Se pueden extraer proxies v√°lidos
- [ ] ‚úÖ Se detecta estructura de paginaci√≥n
- [ ] ‚úÖ Rate limiting es manejable
- [ ] ‚úÖ Formato de datos es consistente
- [ ] ‚úÖ No hay blocking inmediato

---

## üéØ Criterios de √âxito del MVP

### **‚úÖ MVP EXITOSO si:**

1. **Extrae al menos 10 proxies v√°lidos** de la primera p√°gina
2. **Detecta estructura de paginaci√≥n** correctamente
3. **No recibe errores 403/429** inmediatamente
4. **Formato de datos es consistente** y parseable
5. **Tiempo de respuesta < 10 segundos**

### **‚ùå MVP FALLIDO si:**

- Cloudflare o protecci√≥n anti-bot bloquea requests
- Estructura DOM es demasiado din√°mica/cambiante
- Rate limiting muy agresivo (< 1 request/minuto)
- Datos est√°n en JavaScript din√°mico (no HTML est√°tico)
- Requiere autenticaci√≥n obligatoria

---

## üìà Siguientes Pasos seg√∫n Resultados

### **üü¢ Si MVP es EXITOSO:**

1. Proceder con el desarrollo completo seg√∫n `TASKS.md`
2. Usar learnings del MVP para optimizar selectores
3. Implementar delays basados en testing real
4. A√±adir estrategias de fallback identificadas

### **üü° Si MVP es PARCIAL:**

1. Identificar problemas espec√≠ficos
2. Ajustar estrategias de scraping
3. Considerar usar Playwright desde el inicio
4. Evaluar proxies alternativos para scraping

### **üî¥ Si MVP FALLA:**

1. Analizar causa ra√≠z del fallo
2. Evaluar p√°ginas alternativas de proxies
3. Considerar APIs de terceros
4. Replantear arquitectura del proyecto

---

**üí° Tiempo estimado del MVP: 2-4 horas**

Este MVP nos dar√° la confianza necesaria para proceder con el desarrollo completo, o nos alertar√° sobre problemas potenciales antes de invertir tiempo en la aplicaci√≥n full-stack.
