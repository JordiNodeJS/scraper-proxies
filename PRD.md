# PRD - Scraper de Proxies con ValidaciÃ³n

## ğŸ“‹ Resumen Ejecutivo

**Nombre del Proyecto:** Scraper de Proxies con ValidaciÃ³n
**VersiÃ³n:** 1.0.0
**Fecha:** 2024
**Tipo:** Single Page Application (SPA) React con TypeScript

### DescripciÃ³n
AplicaciÃ³n web React que extrae proxies desde hide.mn, los valida mediante Playwright y presenta los resultados funcionales en una interfaz moderna y responsiva.

## ğŸ¯ Objetivos del Producto

### Objetivo Principal
Desarrollar una herramienta automatizada que permita extraer, validar y presentar proxies funcionales de manera eficiente y confiable.

### Objetivos EspecÃ­ficos
1. **ExtracciÃ³n AutomÃ¡tica**: Scraping completo de todas las pÃ¡ginas de proxies
2. **ValidaciÃ³n en Tiempo Real**: VerificaciÃ³n de funcionalidad de cada proxy
3. **Interfaz Intuitiva**: PresentaciÃ³n clara y organizada de resultados
4. **Performance**: OptimizaciÃ³n para manejar grandes volÃºmenes de datos

## ğŸ‘¥ Usuarios Objetivo

- **Desarrolladores**: Que necesiten proxies para testing o desarrollo
- **Administradores de Red**: Para anÃ¡lisis de conectividad
- **Investigadores de Seguridad**: Para auditorÃ­as y pruebas de penetraciÃ³n

## âš¡ Funcionalidades Core

### 1. ExtracciÃ³n de Proxies (Scraping)
**Fuente:** https://hide.mn/es/proxy-list/?type=s#list

#### Especificaciones TÃ©cnicas:
- **LibrerÃ­a:** Cheerio para parsing HTML
- **MÃ©todo:** NavegaciÃ³n automÃ¡tica por paginaciÃ³n
- **DetecciÃ³n de PÃ¡ginas:** AnÃ¡lisis del DOM para determinar total de pÃ¡ginas
- **Estructura de Datos:**
  ```typescript
  interface Proxy {
    ip: string;
    port: number;
    protocol: 'http' | 'https';
    country?: string;
    anonymity?: string;
    lastChecked?: Date;
  }
  ```

#### Proceso de ExtracciÃ³n:
1. **AnÃ¡lisis Inicial**: Detectar estructura de paginaciÃ³n
2. **IteraciÃ³n Secuencial**: Navegar pÃ¡gina por pÃ¡gina
3. **Parsing de Datos**: Extraer IP, puerto y protocolo
4. **Almacenamiento Temporal**: Array en memoria para procesamiento

### 2. ValidaciÃ³n de Proxies
**Herramienta:** Playwright para testing automatizado

#### Criterios de ValidaciÃ³n:
- **Test BÃ¡sico**: Solicitud GET a https://example.com
- **MÃ©tricas Registradas:**
  - Latencia de respuesta (ms)
  - Estado de conexiÃ³n (exitoso/fallido)
  - Tiempo de timeout
  - CÃ³digo de respuesta HTTP

#### ConfiguraciÃ³n de Playwright:
```typescript
interface ValidationConfig {
  timeout: number; // 10000ms por defecto
  retries: number; // 2 intentos por defecto
  concurrency: number; // 5 conexiones simultÃ¡neas
}
```

#### Proceso de ValidaciÃ³n:
1. **ConfiguraciÃ³n de Proxy**: Setup de Playwright con proxy
2. **EjecuciÃ³n de Test**: Request a endpoint de prueba
3. **MediciÃ³n de MÃ©tricas**: Captura de latencia y estado
4. **Filtrado**: Solo proxies exitosos pasan al resultado final

### 3. Frontend React

#### Estructura de Componentes:
```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ProxyTable/
â”‚   â”‚   â”œâ”€â”€ ProxyTable.tsx
â”‚   â”‚   â”œâ”€â”€ ProxyRow.tsx
â”‚   â”‚   â””â”€â”€ Pagination.tsx
â”‚   â”œâ”€â”€ Controls/
â”‚   â”‚   â”œâ”€â”€ ActionButton.tsx
â”‚   â”‚   â””â”€â”€ StatusIndicator.tsx
â”‚   â””â”€â”€ Layout/
â”‚       â”œâ”€â”€ Header.tsx
â”‚       â””â”€â”€ Container.tsx
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useProxyScraper.ts
â”‚   â”œâ”€â”€ useProxyValidator.ts
â”‚   â””â”€â”€ usePagination.ts
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ scraperService.ts
â”‚   â”œâ”€â”€ validatorService.ts
â”‚   â””â”€â”€ apiService.ts
â”œâ”€â”€ types/
â”‚   â””â”€â”€ proxy.types.ts
â””â”€â”€ utils/
    â”œâ”€â”€ helpers.ts
    â””â”€â”€ constants.ts
```

#### Funcionalidades de UI:

##### Tabla de Proxies
- **PaginaciÃ³n**: 10 proxies por pÃ¡gina
- **Columnas Mostradas:**
  - IP Address
  - Puerto
  - Protocolo
  - Latencia
  - Estado
  - PaÃ­s (si disponible)
- **Ordenamiento**: Por latencia, estado, IP
- **Filtros**: Por protocolo, estado, rango de latencia

##### Controles de AcciÃ³n
- **BotÃ³n Principal**: "Iniciar Scraping"
- **Estados del BotÃ³n:**
  - Idle: "Iniciar Scraping"
  - Loading: "Extrayendo..." con spinner
  - Validating: "Validando..." con progreso
  - Complete: "Reiniciar Proceso"
- **BotÃ³n Secundario**: "Limpiar Resultados"

##### Indicadores de Estado
- **Barra de Progreso**: Durante extracciÃ³n y validaciÃ³n
- **Contador en Tiempo Real**: Proxies encontrados/validados
- **Notificaciones**: Toast para errores o completado
- **Estado de ConexiÃ³n**: Indicador de conexiÃ³n a internet

## ğŸ› ï¸ Especificaciones TÃ©cnicas

### Stack TecnolÃ³gico
- **Frontend**: React 19.1.0 + TypeScript
- **Build Tool**: Vite 6.3.5
- **Styling**: CSS Modules / Tailwind CSS
- **Scraping**: Cheerio + Axios
- **Testing**: Playwright
- **State Management**: React Context + useReducer
- **Linting**: ESLint con configuraciÃ³n TypeScript

### Arquitectura de la AplicaciÃ³n

#### PatrÃ³n de Estado
```typescript
interface AppState {
  proxies: Proxy[];
  validatedProxies: Proxy[];
  isLoading: boolean;
  isValidating: boolean;
  currentPage: number;
  totalPages: number;
  error: string | null;
  progress: {
    scraped: number;
    validated: number;
    total: number;
  };
}
```

#### Flujo de Datos
1. **Usuario Inicia Proceso** â†’ Dispatch de acciÃ³n SCRAPING_START
2. **Scraper Service** â†’ Extrae proxies y actualiza estado
3. **Validator Service** â†’ Valida proxies en lotes
4. **UI Update** â†’ Reactiva renderiza tabla con resultados

### ConfiguraciÃ³n de Desarrollo

#### Scripts de Package.json
```json
{
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "lint": "eslint .",
    "preview": "vite preview",
    "test": "vitest",
    "scrape": "tsx scripts/scraper.ts"
  }
}
```

#### Dependencias Requeridas
```json
{
  "dependencies": {
    "react": "^19.1.0",
    "react-dom": "^19.1.0",
    "axios": "^1.6.0",
    "cheerio": "^1.0.0-rc.12",
    "@playwright/test": "^1.40.0"
  }
}
```

### Reglas de CodificaciÃ³n

#### ESLint Configuration
- **Base**: @eslint/js recommended + TypeScript recommended
- **React Rules**: react-hooks recommended + react-refresh
- **Globals**: Browser environment
- **Ignored**: dist/ directory

#### Convenciones de CÃ³digo
- **Formato**: TypeScript estricto
- **Naming**: camelCase para variables, PascalCase para componentes
- **Imports**: Absolutos con alias configurados
- **Comentarios**: JSDoc para funciones pÃºblicas

#### Estructura de Archivos
- **Componentes**: Un componente por archivo
- **Hooks**: Prefijo 'use' obligatorio
- **Tipos**: Sufijo '.types.ts'
- **Servicios**: Sufijo '.service.ts'

## ğŸ“Š MÃ©tricas y Performance

### KPIs del Sistema
- **Tiempo de ExtracciÃ³n**: < 30 segundos para todas las pÃ¡ginas
- **Tasa de ValidaciÃ³n**: 80% de proxies procesados en < 2 minutos
- **Latencia UI**: < 100ms para interacciones
- **PrecisiÃ³n**: > 95% de proxies validados funcionan correctamente

### Optimizaciones
- **Concurrencia**: MÃ¡ximo 5 validaciones simultÃ¡neas
- **Caching**: Resultados vÃ¡lidos por 1 hora
- **Lazy Loading**: Tabla virtualizada para > 100 resultados
- **Error Handling**: Retry automÃ¡tico con backoff exponencial

## ğŸš€ Roadmap de Desarrollo

### Fase 1: Core Functionality (Semana 1-2)
- [ ] Setup inicial del proyecto
- [ ] ImplementaciÃ³n del scraper base
- [ ] Validador bÃ¡sico con Playwright
- [ ] UI mÃ­nima funcional

### Fase 2: Enhancement (Semana 3)
- [ ] PaginaciÃ³n avanzada
- [ ] Indicadores de progreso
- [ ] Manejo de errores robusto
- [ ] Testing unitario

### Fase 3: Polish (Semana 4)
- [ ] UI/UX refinamiento
- [ ] Optimizaciones de performance
- [ ] DocumentaciÃ³n completa
- [ ] Testing end-to-end

## ğŸ” Casos de Uso

### Caso de Uso 1: ExtracciÃ³n Completa
**Actor**: Usuario
**Flujo Principal:**
1. Usuario hace clic en "Iniciar Scraping"
2. Sistema navega hide.mn y extrae todos los proxies
3. Sistema valida cada proxy automÃ¡ticamente
4. Sistema muestra resultados en tabla paginada

### Caso de Uso 2: Re-validaciÃ³n
**Actor**: Usuario
**Flujo Principal:**
1. Usuario hace clic en "Reiniciar Proceso"
2. Sistema limpia resultados anteriores
3. Sistema ejecuta extracciÃ³n y validaciÃ³n nuevamente
4. Sistema actualiza tabla con nuevos resultados

### Caso de Uso 3: Filtrado de Resultados
**Actor**: Usuario
**Flujo Principal:**
1. Usuario selecciona filtros (protocolo, latencia)
2. Sistema filtra tabla en tiempo real
3. PaginaciÃ³n se ajusta automÃ¡ticamente
4. URL se actualiza para mantener estado

## âš ï¸ Consideraciones de Riesgo

### Riesgos TÃ©cnicos
- **Rate Limiting**: hide.mn puede limitar requests
- **Estructura de PÃ¡gina**: Cambios en DOM pueden romper scraper
- **Proxy Reliability**: Alta tasa de proxies no funcionales

### Mitigaciones
- **Throttling**: Delays entre requests para evitar blocking
- **Selectors Flexibles**: XPath y CSS selectors robustos
- **Error Recovery**: Manejo graceful de fallos de validaciÃ³n

## ğŸ“ˆ MÃ©tricas de Ã‰xito

### TÃ©cnicas
- Time to First Proxy: < 10 segundos
- Validation Success Rate: > 30%
- UI Responsiveness: < 200ms

### Funcionales
- User Completion Rate: > 90%
- Error Rate: < 5%
- Proxy Accuracy: > 95%

## ğŸ”§ ConfiguraciÃ³n del Entorno

### Variables de Entorno
```env
VITE_SCRAPING_DELAY=2000
VITE_VALIDATION_TIMEOUT=10000
VITE_MAX_CONCURRENT_VALIDATIONS=5
VITE_RESULTS_CACHE_TTL=3600000
```

### Comandos de Desarrollo
```bash
# InstalaciÃ³n
npm install

# Desarrollo
npm run dev

# Build de producciÃ³n
npm run build

# Linting
npm run lint

# Testing
npm run test
```

---

**Documento de Referencia para IA Cursor**
Este PRD sirve como guÃ­a completa para el desarrollo del scraper de proxies. Contiene todas las especificaciones tÃ©cnicas, reglas de codificaciÃ³n y estÃ¡ndares que deben seguirse durante el desarrollo. 